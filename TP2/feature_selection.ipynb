{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import  RobustScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile, GenericUnivariateSelect\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.utils import shuffle\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import f_classif, chi2\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, SGDClassifier, LassoCV\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AbsenteeismAtWork = pd.read_csv('data/train_data.csv', index_col=0)\n",
    "AbsenteeismAtWork['Work load Average/day '] = [x.replace(',', '') for x in AbsenteeismAtWork['Work load Average/day ']]\n",
    "AbsenteeismAtWork['Work load Average/day '] = AbsenteeismAtWork['Work load Average/day '].astype(int)\n",
    "\n",
    "X_train = AbsenteeismAtWork.drop('Absent', 1)\n",
    "y_train =  AbsenteeismAtWork['Absent']\n",
    "X_test = pd.read_csv('data/test_data.csv', index_col=0)\n",
    "y_test = pd.read_csv('data/sample_submission.csv', index_col=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robustScaling2(X_train, X_test):\n",
    "    scaler = RobustScaler()\n",
    "    scaled_data = scaler.fit_transform( X_train )\n",
    "    scaled_test = scaler.transform( X_test )\n",
    "    return scaled_data, scaled_test;\n",
    "\n",
    "def overSampler(X_train, y_train):\n",
    "    ros = RandomOverSampler()\n",
    "    X_balanced, y_train = ros.fit_sample(X_train, y_train)\n",
    "    X_balanced, y_train = shuffle(X_balanced, y_train)\n",
    "    return X_balanced, y_train;\n",
    "\n",
    "def evaluateSelector(featureSelector, selectorName):\n",
    "    X_train = AbsenteeismAtWork.drop('Absent', 1)\n",
    "    y_train =  AbsenteeismAtWork['Absent']\n",
    "    X_test = pd.read_csv('data/test_data.csv', index_col=0)\n",
    "    y_test = pd.read_csv('data/sample_submission.csv', index_col=0)\n",
    "\n",
    "    \n",
    "    # Feature Selection\n",
    "    X_train_selected, X_test_selected = featureSelector(X_train, y_train, X_test)\n",
    "    \n",
    "    # standardizar\n",
    "    X_train_transformed, X_test_transformed = robustScaling2(X_train_selected, X_test_selected)\n",
    "    \n",
    "    \n",
    "    classifiers = [\n",
    "        LogisticRegression(),\n",
    "        SGDClassifier(),\n",
    "        KNeighborsClassifier(n_neighbors=5),\n",
    "        SVC(),\n",
    "        LinearSVC(max_iter=10000),\n",
    "        GaussianNB(),\n",
    "        GaussianProcessClassifier(),\n",
    "        DecisionTreeClassifier(),\n",
    "        MLPClassifier(max_iter=10000),\n",
    "        AdaBoostClassifier(),\n",
    "        RandomForestClassifier(),\n",
    "    ]\n",
    "    \n",
    "    names = [\n",
    "             \"Logistic regression\", \"SGDClassifier\",\n",
    "             \"KNearest Neighbors (5)\", \n",
    "             \"SVM-rbf\", \"SMV-linear\", \n",
    "             \"Gaussian naive bayes\",\n",
    "             \"Gaussian Process\", \n",
    "             \"Decision Tree\", \n",
    "             \"Multi-layer Perceptron\", \n",
    "             \"AdaBoost\", \"Random Forest\"]\n",
    "    \n",
    "    # Treinar e avaliar modelos\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        clf.fit(X_train_transformed, y_train)\n",
    "        predicted = clf.predict(X_test_transformed)\n",
    "        evaluateModel(name + \" com \" + selectorName, y_test, predicted)\n",
    "    return;\n",
    "\n",
    "\n",
    "def evaluateModelBasedSelector(featureSelector, model, name):\n",
    "    X_train = AbsenteeismAtWork.drop('Absent', 1)\n",
    "    y_train =  AbsenteeismAtWork['Absent']\n",
    "    X_test = pd.read_csv('data/test_data.csv', index_col=0)\n",
    "    y_test = pd.read_csv('data/sample_submission.csv', index_col=0)\n",
    "\n",
    "    # Feature Selection\n",
    "    X_train_selected, X_test_selected = featureSelector(X_train, y_train, X_test)\n",
    "    \n",
    "    \n",
    "    # Normalizar, discretizar ou standardizar\n",
    "    X_train_transformed, X_test_transformed = robustScaling2(X_train_selected, X_test_selected)\n",
    "    \n",
    "    # Treinar modelo\n",
    "    model.fit(X_train_transformed, y_train)\n",
    "    \n",
    "    # Prever resultados para test set\n",
    "    predicted = model.predict(X_test_transformed)\n",
    "    \n",
    "    # Avaliar modelo\n",
    "    evaluateModel(name, y_test, predicted)\n",
    "    return;\n",
    "\n",
    "def evaluateModel(name, y_test, predicted):\n",
    "    print(\"Accuracy: %0.3f || AUROC %0.3f || (Accuracy, Precision) 0:( %0.3f, %0.3f)  1:( %0.3f, %0.3f) ->\" \n",
    "              % (accuracy_score(y_test,predicted), roc_auc_score(y_test, predicted),\n",
    "                recall_score(y_test,predicted,pos_label=0), precision_score(y_test,predicted,pos_label=0),\n",
    "                recall_score(y_test,predicted,pos_label=1), precision_score(y_test,predicted,pos_label=1)), name)\n",
    "    return;\n",
    "\n",
    "\n",
    "def getPickedFeatures(selector, data):\n",
    "    selected_features_index = selector.get_support(indices=True)\n",
    "    dropped_features_index = list( set(list(range(0, data.columns.size))) - (set(selected_features_index)))\n",
    "\n",
    "    selected_features_names = list(data.columns[selected_features_index])\n",
    "    return selected_features_names;\n",
    "\n",
    "\n",
    "def getDroppedFeatures(selector, data):\n",
    "    selected_features_index = selector.get_support(indices=True)\n",
    "    dropped_features_index = list( set(list(range(0, data.columns.size))) - (set(selected_features_index)))\n",
    "\n",
    "    dropped_features_names = list(data.columns[dropped_features_index])\n",
    "    return dropped_features_names;\n",
    "\n",
    "\n",
    "def printFeatureSelection(selector, data):\n",
    "    selected_features_index = selector.get_support(indices=True)\n",
    "    dropped_features_index = list( set(list(range(0, data.columns.size))) - (set(selected_features_index)))\n",
    "\n",
    "    selected_features_names = zip(selected_features_index,  list(data.columns[selected_features_index]))\n",
    "    dropped_features_names = zip(dropped_features_index, list(data.columns[dropped_features_index]))\n",
    "\n",
    "    print(\"Features mantidas:\")\n",
    "    for cn in selected_features_names:\n",
    "        print(\"\\t\" + str(cn))\n",
    "\n",
    "    print(\"Features eliminadas:\")\n",
    "    for cn in dropped_features_names:\n",
    "        print(\"\\t\" + str(cn))\n",
    "    return;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções auxiliares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectVarianceThreshold(X_train, y_train, X_test):\n",
    "    varianceThreshold_selector = VarianceThreshold()\n",
    "    selector = varianceThreshold_selector.fit(X_train, y_train)\n",
    "    #printFeatureSelection(selector, X_train)\n",
    "    X_train_selected = varianceThreshold_selector.transform(X_train)\n",
    "    X_test_selected = varianceThreshold_selector.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelectKBest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Choosing a K Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbest_svc_accuracy = []\n",
    "kbest_knn_accuracy = []\n",
    "kbest_logreg_accuracy = []\n",
    "\n",
    "for i in range(1,19):\n",
    "    \n",
    "    X_train_transformed, X_test_transformed = robustScaling2(X_train, X_test)\n",
    "    X_train_balanced, y_train_balanced = overSampler(X_train_transformed, y_train)\n",
    "    \n",
    "    selectKBest = SelectKBest(f_classif, k=i)\n",
    "    selectKBest.fit(X_train_balanced,y_train_balanced)\n",
    "    X_train_selected = selectKBest.transform(X_train_balanced)\n",
    "    X_test_selected = selectKBest.transform(X_test_transformed)\n",
    "    \n",
    "    svc = SVC().fit(X_train_selected, y_train_balanced)\n",
    "    pred_i_svc_kbest = svc.predict(X_test_selected)\n",
    "    pred_i_svc_kbest_accuracy = accuracy_score(y_test, pred_i_svc_kbest)\n",
    "    kbest_svc_accuracy.append(pred_i_svc_kbest_accuracy)\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=5).fit(X_train_selected, y_train_balanced)\n",
    "    pred_i_knn_kbest = knn.predict(X_test_selected)\n",
    "    pred_i_knn_kbest_accuracy = accuracy_score(y_test, pred_i_knn_kbest)\n",
    "    kbest_knn_accuracy.append(pred_i_knn_kbest_accuracy)\n",
    "\n",
    "    logreg = LogisticRegression(max_iter=10000).fit(X_train_selected, y_train_balanced)\n",
    "    pred_i_logreg_kbest = logreg.predict(X_test_selected)\n",
    "    pred_i_logreg_kbest_accuracy = accuracy_score(y_test, pred_i_logreg_kbest)\n",
    "    kbest_logreg_accuracy.append(pred_i_logreg_kbest_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,19),kbest_svc_accuracy, color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=10, label='SVC')\n",
    "plt.plot(range(1,19),kbest_knn_accuracy, color='green', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='yellow', markersize=10, label='KNeighborsClassifier(5)')\n",
    "plt.plot(range(1,19),kbest_logreg_accuracy, color='black', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='silver', markersize=10, label='LogisticRegression')\n",
    "plt.legend()\n",
    "plt.title('Accuracy vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectKBest_f_classif(X_train, y_train, X_test):\n",
    "    kbest_selector_f_classif = SelectKBest(f_classif, k=2)\n",
    "    selector = kbest_selector_f_classif.fit(X_train, y_train)\n",
    "    #printFeatureSelection(selector, X_train)\n",
    "    X_train_selected = kbest_selector_f_classif.transform(X_train)\n",
    "    X_test_selected = kbest_selector_f_classif.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;\n",
    "\n",
    "def selectKBest_chi2(X_train, y_train, X_test):\n",
    "    kbest_selector_chi2 = SelectKBest(chi2, k=1)\n",
    "    selector = kbest_selector_chi2.fit(X_train, y_train)\n",
    "    #printFeatureSelection(selector, X_train)\n",
    "    X_train_selected = kbest_selector_chi2.transform(X_train)\n",
    "    X_test_selected = kbest_selector_chi2.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelectPercentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectPercentile_f_classif(X_train, y_train, X_test):\n",
    "    percentile_selector_f_classif = SelectPercentile(f_classif, percentile=10)\n",
    "    selector = percentile_selector_f_classif.fit(X_train, y_train)\n",
    "    X_train_selected = percentile_selector_f_classif.transform(X_train)\n",
    "    X_test_selected = percentile_selector_f_classif.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;\n",
    "\n",
    "def selectPercentile_chi2(X_train, y_train, X_test):\n",
    "    percentile_selector_chi2 = SelectPercentile(chi2, percentile=10)\n",
    "    selector = percentile_selector_chi2.fit(X_train, y_train)\n",
    "    X_train_selected = percentile_selector_chi2.transform(X_train)\n",
    "    X_test_selected = percentile_selector_chi2.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GenericUnivariateSelect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectGenericUnivariateSelect(X_train, y_train, X_test):\n",
    "    gus_selector = GenericUnivariateSelect(f_classif, 'k_best', param=19)\n",
    "    selector = gus_selector.fit(X_train, y_train)\n",
    "    X_train_selected = gus_selector.transform(X_train)\n",
    "    X_test_selected = gus_selector.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfeLogReg(X_train, y_train, X_test):\n",
    "    rfe_log_selector = RFE(LogisticRegression(), 12)\n",
    "    selector = rfe_log_selector.fit(X_train, y_train)\n",
    "    #printFeatureSelection(selector, X_balanced)\n",
    "    X_train_selected = rfe_log_selector.transform(X_train)\n",
    "    X_test_selected = rfe_log_selector.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;\n",
    "\n",
    "\n",
    "def rfeSVC(X_train, y_train, X_test):\n",
    "    rfe_svc_selector = RFE(SVC(kernel='linear'), 12)\n",
    "    selector = rfe_svc_selector.fit(X_train, y_train)\n",
    "    #printFeatureSelection(selector, X_balanced)\n",
    "    X_train_selected = rfe_svc_selector.transform(X_train)\n",
    "    X_test_selected = rfe_svc_selector.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recursive Feature Elimination w/ Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfeCvLogReg(X_train, y_train, X_test):\n",
    "    rfecv_log_selector = RFECV(LogisticRegression(), 12)\n",
    "    selector = rfecv_log_selector.fit(X_train, y_train)\n",
    "    #printFeatureSelection(selector, X_balanced)\n",
    "    X_train_selected = rfecv_log_selector.transform(X_train)\n",
    "    X_test_selected = rfecv_log_selector.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;\n",
    "\n",
    "def rfeCvSVC(X_train, y_train, X_test):\n",
    "    rfecv_svc_selector = RFECV(SVC(kernel='linear'), 12)\n",
    "    selector = rfecv_svc_selector.fit(X_train, y_train)\n",
    "    #printFeatureSelection(selector, X_balanced)\n",
    "    X_train_selected = rfecv_svc_selector.transform(X_train)\n",
    "    X_test_selected = rfecv_svc_selector.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelectFromModel Tree-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sfmTree(X_train, y_train, X_test):\n",
    "    tree_selector = ExtraTreesClassifier(n_estimators=50)\n",
    "    selector = tree_selector.fit(X_train, y_train)\n",
    "    sfm_Tree_selector = SelectFromModel(tree_selector, prefit=True)\n",
    "    #printFeatureSelection(selector, X_balanced)\n",
    "    X_train_selected = sfm_Tree_selector.transform(X_train)\n",
    "    X_test_selected = sfm_Tree_selector.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectPCA(X_train, y_train, X_test):\n",
    "    pca_selector = PCA(n_components=2)\n",
    "    selector = pca_selector.fit(X_train, y_train)\n",
    "    #printFeatureSelection(selector, X_balanced)\n",
    "    X_train_selected = pca_selector.transform(X_train)\n",
    "    X_test_selected = pca_selector.transform(X_test)\n",
    "    \n",
    "    return X_train_selected, X_test_selected;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Evaluate different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and Training the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing features with low variance\n",
    "\n",
    "evaluateSelector(selectVarianceThreshold, \"VarianceThreshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate feature selection\n",
    "print(\"Com f_classif\\n\\n\")\n",
    "evaluateSelector(selectKBest_f_classif, \"Select k best f_classif\")\n",
    "\n",
    "print(\"\\n\\nCom qui2\\n\\n\")\n",
    "evaluateSelector(selectKBest_chi2, \"Select k best qui2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Com f_classif\\n\\n\")\n",
    "evaluateSelector(selectPercentile_f_classif, \"Select Percentile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateSelector(selectGenericUnivariateSelect, \"Generic univariate select\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive feature elimination\n",
    "\n",
    "#evaluateModelBasedSelector( rfeLogReg,  LogisticRegression(), \"Log Reg w/ RFE LogReg\")\n",
    "evaluateModelBasedSelector( rfeCvLogReg, LogisticRegression(), \"Log Reg w/ RFE Cross Validation LogReg\")\n",
    "\n",
    "#evaluateModelBasedSelector( rfeSVC, SVC(kernel='linear'), \"SVC Linear w/ RFE SVC\")\n",
    "#evaluateModelBasedSelector( rfeCvSVC, SVC(kernel='linear'), \"SVC Linear w/ RFE Cross Validation SVC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection using SelectFromModel\n",
    "\n",
    "evaluateModelBasedSelector( sfmTree, SVC(kernel='linear'), \"SVC Linear w/ SelectFromModel Tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection using PCA\n",
    "\n",
    "evaluateSelector(selectPCA, \"PCA\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
